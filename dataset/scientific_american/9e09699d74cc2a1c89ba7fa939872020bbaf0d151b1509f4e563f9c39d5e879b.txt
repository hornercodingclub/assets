Read Our Latest Issue By channeling a flood of biomedical data, machine learning could transform basic research and clinical practice THE BIOMEDICAL WORLD IS AWASH IN DATA. We have terabytes of genomic information from mouse to human, troves of health metrics from clinical trials, and reams of so-called real-world data from insurance companies and pharmacies. Using powerful computers, scientists have scrutinized this bounty with some fine results, but it has become clear that we can learn much more with an assist from artificial intelligence. Over the next decade deep-learning neural networks will likely transform how we look for patterns in data and how research is conducted and applied to human health. This special report explores the promise of this nascent revolution. Right now the biggest bets are being placed in the realm of drug discovery. And for good reason. The average cost of bringing a new drug to market nearly doubled between 2003 and 2013 to $2.6 billion, and because nine out of 10 fail in the final two phases of clinical trials, most of the money goes to waste. Every large pharma company is working with at least one AI-focused start-up to see if it can raise the return on investment. Machine-learning algorithms can sift through millions of compounds, narrowing the options for a particular drug target. Perhaps more exciting, AI systems--unconstrained by prevailing theories and biases--can identify entirely new targets by spotting subtle differences at the level of tissues, cells, genes or proteins between, say, a healthy brain and one marked by Parkinson's--differences that might elude or even mystify a human scientist. That same sharp-eyed ability is also being deployed to interpret medical scans. Some systems can already detect early signs of cancer that might be missed by a radiologist or see things that are simply beyond human capacity--such as assessing cardiovascular risk from a retinal scan. The Food and Drug Administration is approving imaging algorithms at a rapid clip. Other AI applications lie a bit further down the road. Will the inefficiencies of today's electronic health records (EHRs) be addressed by smart systems that prevent prescribing errors and provide early warnings of disease? Some of the world's biggest tech giants are working on it. Despite fears that machines will displace humans, most experts believe artificial and human intelligence will work synergistically. The bigger concern is a shortage of people with both biomedical knowledge and algorithm-building proficiency. If this human problem can be resolved, the key to creating successful AI applications may depend on the quality and quantity of what we feed their hungry maw. "We rely on three things," says the CEO of one deep-learning start-up. "Data, data and more data." This report, published in and , is sponsored by F. Hoffmann-La Roche Ltd. It was produced independently by the editors of , who take sole responsibility for the editorial content. Claudia Wallis is an award-winning science journalist whose work has appeared in the and the . She was science editor at and managing editor of Credit: Nick Higgins 6 hours ago  --  Robert Z. Pearlman and SPACE.com 7 hours ago  --  Nidhi Subbaraman and Nature magazine 8 hours ago  --  Jean Chemnick and E&E News 14 hours ago  --  Avi Loeb | 15 hours ago  --  Marla Broadfoot January 25, 2021  --  Chelsea Harvey and E&E News Discover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.