Read Our Latest Issue Read Our Latest Issue Why so many people choose not to believe what scientists say A friend of mine has long held that a vaccination his son received as an infant triggered his child's autism. He clings to this belief despite a string of scientific studies that show no link between autism and vaccines. When the original paper on such a link was discredited as a fraud, my friend's reaction was that it would become more difficult to persuade people of the dangers of vaccination. He is not alone: nearly half of all Americans believe in the vaccine-autism link or are unsure about it. The paradox goes deeper. My friend insists that he trusts scientists--and again, in this respect, he is like most Americans. In a 2016 survey by the National Science Foundation, more respondents expressed "a great deal" of confidence in science leaders than in leaders of any other institution except the military. On public policy issues, Americans believe that science leaders are more knowledgeable and impartial than leaders in other sectors of society, such as business or government. Why do people say that they trust scientists in general but part company with them on specific issues? Many individuals blame the poor quality of science education in the U.S. If kids got more science in school, the thinking goes, they would learn to appreciate scientific opinion on vaccines, climate, evolution and other policy issues. But this is a misconception. Those who know more science have only a slightly greater propensity to trust scientists. The science behind many policy issues is highly specialized, and evaluating it requires deep knowledge--deeper than students are going to get in elementary and high school science classes. A more direct approach would be to educate people about why they are prone to accept inaccurate beliefs in the first place. Humans do seem to prize accuracy above all. We want our beliefs to be accurate--to align with what is really true about the world--and we know that science is a reliable guide to accuracy. But this desire to be accurate conflicts with other motives, some of them unconscious. People hold beliefs to protect important values, for example. Individuals who think of nature as sacred may perceive genetic modification as morally wrong, regardless of its safety or utility. People also hold beliefs that are rooted in their emotions. A flu pandemic that can cause widespread death among the innocent may cause feelings of fear and helplessness. One way to cope with those emotions is to belittle warnings of a pandemic as improbable. In reconciling our rational and irrational motives for belief, we have become good at kidding ourselves. Because we want to see ourselves as rational beings, we find reasons to maintain that our beliefs accurate. One or two contrarians are sufficient to convince us that the science is "controversial" or "unsettled." If people knew that other motives might compromise the accuracy of their beliefs, most would probably try to be on their guard. Asking science teachers to impart enough content to understand all the issues may be unrealistic, but they might be able to improve people's appreciation for the accuracy of scientific knowledge. Through the study of the history of science, students might gain an understanding both of their own motivations for belief and of science as a method of knowing. If a student understands how a medieval worldview could have made a geocentric theory of the solar system seem correct, it is a short step to seeing similar influences in oneself. Science history can also help students understand why scientific knowledge grows ever more accurate. It is easy for a nonscientist to dismiss an unpleasant conclusion as controversial on the grounds that scientists constantly change their minds: "First they say chocolate is bad for us, then it's good ... they can't decide anything." By studying how new observations led to the revision of important theories, however, students see that science is not about immutable laws but provisional explanations that get revised when a better one comes along. They also see that scientists' readiness to change their beliefs to align with data is a source of great strength, not weakness, and why near consensus on issues such as global warming or vaccine safety is so impressive. Science may not be the only way of organizing and understanding our experience, but for accuracy it fares better than religion, politics and art. That's the lesson. This article was originally published with the title "Trust Me, I'm a Scientist" in Scientific American  304, 5,  (May 2011) doi:10.1038/scientificamerican0511-12 Daniel T. Willingham is professor of psychology at the University of Virginia and is author of (Jossey-Bass, 2009). 6 hours ago  --  Robert Z. Pearlman and SPACE.com 7 hours ago  --  Nidhi Subbaraman and Nature magazine 8 hours ago  --  Jean Chemnick and E&E News 15 hours ago  --  Avi Loeb | 15 hours ago  --  Marla Broadfoot January 25, 2021  --  Chelsea Harvey and E&E News Discover new insights into neuroscience, human behavior and mental health with Scientific American Mind. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.