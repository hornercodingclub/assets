Read Our Latest Issue Truly autonomous automobiles do not exist. Will things change once cars can think like people? Early attempts at have had little difficulty gathering the loads of data required to operate autonomously. Automakers and researchers--at Google, most notably-- driven in vehicles laden with Internet servers, GPS, radar, lasers, cameras and a variety of other onboard sensors. The : Self-driven vehicles have demonstrated the ability to measure and maintain their distance from other automobiles and even obey traffic laws.  Still, there are good reasons these vehicles should always have a person behind the wheel, just in case. Humans are capable of making split-second decisions based on memory and the body's collective senses. Despite all the advanced hardware developed to create autonomous automobiles, such vehicles lack a central processing system--a mind--that can make them truly able to make quick sense of and act on data their sensors collect.   One challenge in programming automotive brains to make the kind of snap decisions it takes human drivers years to develop is getting a vehicle to understand its surroundings rather than simply detecting objects, says , a former NASA engineer and designer of unmanned military vehicles. The vehicle does not need to avoid every object it encounters, he adds, "you can drive over a speed bump, but you don't want to drive over a dog--and yet they may be roughly the same size and shape."  The hurdle is making the right decisions in a constantly changing environment, according to , professor of electrical and computer engineering at Carnegie Mellon University. Michigan's hills are harder to navigate than the Nevada flats, and New England snow can obliterate the road markings a car's cameras use to stay in the lane. Even the change from daylight to twilight can throw off a car's sensors.  Traffic adds another dynamic dimension to decision-making. A vehicle's software must act according to the data it receives, even as conditions surrounding the vehicle are continuously in flux. "The software can do the right thing under a particular scenario but the wrong thing in others," says Rajkumar, who has overseen eight generations of Carnegie Mellon autonomous cars, including the Boss SUV that won the DARPA (Defense Advanced Research Projects Agency) . For instance, to avoid a collision, is it better to speed up or slow down?      Most major automakers have shown off demos or at least announced plans to build cars that can drive without human guidance. Many of today's cars come equipped with features that automate various driving tasks and enhance visibility of their surroundings. Some vehicles can park themselves and brake to avoid pedestrians. Cadillac's Super Cruise option may be the closest thing on the market to going driverless--it can take over the accelerator and steering during highway driving."For long trips, you can be hands-free and foot-free," says , director of General Motors' Electrical and Controls Integration Lab.  Yet as smart as today's cars may seem, they are cognitive toddlers. In a car brain, software, processors and an operating system need to run algorithms that determine what the car should do, and these decisions must be made quickly. Sensors and processors made by automotive brake and electronics supplier Continental Automotive Systems, for example, typically transmit and recalculate their algorithms once every 10 to 60 milliseconds. Fast, but not as fast as the , which can pass a message from a sensory neuron, through several interneurons, to a motor neuron within several milliseconds.   Much of the training and testing needed to smarten a driverless car's brain can be done using computer modeling. "You can mimic the operating world in software, run the vehicle virtually in the environment and inject all things it might encounter into it," Rajkumar says.  Continental has spent years categorizing sensor data using a combination of human labeling and machine learning. First, people go through the data captured from millions of kilometers of driving, matching information from cameras and radar, and identifying the most important elements--in particular pedestrians and other vehicles. These manually created labels are used to train software that can then begin to classify images of pedestrians and other vehicles on its own. As the software generates these new labels, Continental developers step in to verify their accuracy. "The first initial inputs are pretty laborious," says Zach Bolton, a Continental project engineer. "The more output you are able to do, the smarter [the software gets], and the less laborious it becomes in the long run."  Eventually, via this labor-intensive training the automotive brain knows that a Mini Cooper and a Ferrari are both cars, and it can tell whether that object ahead is a speed bump or dog. Cars may not be too clever today, Rajkumar notes, but they are well on their way to becoming better drivers than we are. August 23, 2012  --  Susan Kuchinskas May 23, 2011  --  Nick Chambers August 12, 2010  --  Susan Kuchinskas March 29, 2013 Discover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.