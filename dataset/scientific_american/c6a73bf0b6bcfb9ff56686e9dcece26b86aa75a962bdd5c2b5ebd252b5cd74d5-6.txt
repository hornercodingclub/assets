schmancy modeling not going protect weaknesses creep human inference involved notes example human raters videos train facial expression algorithm culture region constrained list labels emotion words anger descriptions scowl casey fiesler assistant professor information science university colorado boulder not involved work expressed concern possibility bias applying categories race authors evaluate influence factor huge body literature speaks example implicit bias judging facial expressions people different races pointed wrong ways assumptions universality facial expression cause harm people marginalized vulnerable economically says nazanin andalibi assistant professor school information science university michigan example earlier facial recognition applications says no matter smiles algorithms continue associate