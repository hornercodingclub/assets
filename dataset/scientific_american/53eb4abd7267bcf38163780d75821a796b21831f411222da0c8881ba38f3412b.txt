Read Our Latest Issue Read Our Latest Issue A new type of brain-imaging technology could expose--even change--our private thoughts The idea of the human mind as the domain of absolute protection from external intrusion has persisted for centuries. Today, however, this presumption might no longer hold. Sophisticated neuroimaging machines and brain-computer interfaces detect the electrical activity of neurons, enabling us to decode and even alter the nervous system signals that accompany mental processes. Whereas these advances have a great potential for research and medicine, they pose a fundamental ethical, legal and social challenge: determining whether or under what conditions it is legitimate to gain access to or interfere with another person's neural activity. This question has special social relevance because many neurotechnologies have moved away from a medical setting and into the commercial domain. Attempts to decode mental information via imaging are also occurring in court cases, sometimes in a scientifically questionable way. For example, in 2008 a woman in India was convicted of murder and sentenced to life imprisonment on the basis of a brain scan showing, according to the judge, "experiential knowledge" about the crime. The potential use of neural technology as a lie detector for interrogation purposes has garnered particular attention. In spite of experts' skepticism, commercial companies are marketing the use of functional MRI- and electroencephalography-based technology to ascertain truth and falsehood. The military is also testing monitoring techniques for another reason: to use brain stimulation to increase a fighter's alertness and attention. Brain-reading technology can be seen as just another unavoidable trend that erodes a bit more of our personal space in the digital world. But given the sanctity of our mental privacy, we might not be so willing to accept this intrusion. People could, in fact, look at this technology as something that requires the reconceptualization of basic human rights and even the creation of neurospecific rights. Lawyers are already talking about a right to cognitive liberty. It would entitle people to make free and competent decisions regarding the use of technology that can affect their thoughts. A right to mental privacy would protect individuals against unconsented-to intrusion by third parties into their brain data, as well as against the unauthorized collection of those data. Breaches of privacy at the neural level could be more dangerous than conventional ones because they can bypass the level of conscious reasoning, leaving us without protections from having our mind read involuntarily. This risk applies not only to predatory marketing studies or to courts using such technology excessively but also to applications that would affect general consumers. This last category is growing. Recently Facebook unveiled a plan to create a speech-to-text interface to translate thoughts directly from brain to computer. Similar attempts are being made by companies such as Samsung and Netflix. In the future, brain control could replace the keyboard and speech recognition as the primary way to interact with computers. If brain-scanning tools become ubiquitous, novel possibilities for misuse will arise--cybersecurity breaches included. Medical devices connected to the brain are vulnerable to sabotage, and neuroscientists at the University of Oxford suggest that the same vulnerability applies to brain implants, leading to the possibility of a phenomenon called brainjacking. Such potential for misuse might prompt us to reconceptualize the right to mental integrity, already recognized as a fundamental human right to mental health. This new understanding would not only protect people from being denied access to treatment for mental illness but would also protect all of us from harmful manipulations of our neural activity through the misuse of technology. Finally, a right to psychological continuity might preserve people's mental life from external alteration by third parties. The same kind of brain interventions being explored to reduce the need for sleep in the military could be adapted to make soldiers more belligerent or fearless. Neurotechnology brings benefits, but to minimize unintended risks, we need an open debate involving neuroscientists, legal experts, ethicists and general citizens. This article was originally published with the title "The Right to Cognitive Liberty" in Scientific American  317, 2, 10 (August 2017) doi:10.1038/scientificamerican0817-10 Marcello Ienca is postdoctoral fellow at the chair of bioethics, Department of Health Sciences and Technology at the Swiss Federal Institute of Technology (ETH Zurich). He is representative to the board of the international neuroethics society. Credit: Nick Higgins 6 hours ago  --  Robert Z. Pearlman and SPACE.com 7 hours ago  --  Nidhi Subbaraman and Nature magazine 8 hours ago  --  Jean Chemnick and E&E News 14 hours ago  --  Avi Loeb | 15 hours ago  --  Marla Broadfoot January 25, 2021  --  Chelsea Harvey and E&E News Discover new insights into neuroscience, human behavior and mental health with Scientific American Mind. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.