Read Our Latest Issue Read Our Latest Issue Updated version of DeepMind's AlphaGo program was behind a mystery online competitor A mystery player causing a stir in the world of the complex strategy game Go has been revealed as an updated version of AlphaGo, the artificial-intelligence (AI) program created by Google's London-based AI firm, DeepMind. Known only by the name 'Master(P)', since late December the anonymous player has beaten the world's best at Go in a string of online games, including defeating current world number one, 19-year-old Ke Jie. Go is regarded as the most complex board game ever invented, and is famously difficult for computers to crack. But last year, AlphaGo showcased the strength of AI software when it , first by defeating a professional human player, Fan Hui, and then going on to . Fellow players had a hunch that Master(P) was probably also an AI program. It came out of nowhere to win dozens of consecutive quick-fire games across two separate online platforms. And on 4 January, Google DeepMind chief executive Demis Hassabis that Master(P) is a new prototype version of AlphaGo. The "unofficial" games were designed to test the prototype, he said: "We're excited by the results and also by what we and the Go community can learn from some of the innovative and successful moves played by the new version of AlphaGo." Playing on the online servers Tygem and FoxGo, Master(P) played more than 50 games, winning in all--except perhaps for one game, which, according to some reports, was deemed a tie only because the network connection of the opponent, the Go professional Chen Yaoye, timed out. "It's extremely impressive whoever/whatever it is," said British Go player Jon Diamond ahead of the announcement. After losing to Master(P), Chinese professional Gu Li offered a reward of 100,000 yuan (US$14,400) to any human who could beat the mysterious player. Although AlphaGo was rumoured to be behind the bot, many observers also suspected that another team had created an AI that could master the game, something both Chinese and South Korean scientists have said they are attempting to do. Hassabis said that the new version of AlphaGo would play official, full-length games later this year. How strong it will be in more high-profile tournaments remains unclear, because the rules of such matches differ from those played in online forums. Online games are usually played at a faster pace, which favours the computer over humans, says Remi Coulom, a freelance developer of Go programs based in Lille, France. "But still, I expect a strong correlation with performance in serious slow tournament games," he adds. AlphaGo has only played around a dozen public games, so Google DeepMind's decision to trial its latest version in the open will allow Go players to study more of its moves. "I personally think it's fantastic that there are all these games for people to look at and study. There are lots of moves that are really new and surprising," says Niall Cardin, a UK-based Go player. Elizabeth Gibney is a senior physics reporter for . December 29, 2016  --  Jesse Emspak October 1, 2015  --  David Pogue March 19, 2016  --  Christof Koch October 24, 2016  --  Larry Greenemeier Discover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.