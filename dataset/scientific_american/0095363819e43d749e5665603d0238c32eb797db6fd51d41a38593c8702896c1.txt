Read Our Latest Issue Neuroscientists are taking cues from cryptography to translate brain activity into movements During World War II, cryptographers cracked Germany's Enigma code by exploiting known language patterns in the encrypted messages. Using the expected frequencies and distributions of certain letters and words helped British computer scientist Alan Turing and his colleagues find the key to translate gibberish into plain language. Now researchers are borrowing from the world of cryptography to convert brain signals into limb movements. Many human motions, such as walking or reaching, follow predictable patterns. With this in mind, Eva Dyer, a neuroscientist at the Georgia Institute of Technology and Emory University, developed a cryptography-inspired strategy for neural decoding. She and her colleagues published their results last December in . "I've heard of this approach before, but this is one of the first studies that's come out and been published," says Nicholas Hatsopoulos, a neuroscientist at the University of Chicago, who was not involved in the work. "It's pretty novel." Existing brain-computer interfaces, such as those that control some prosthetic limbs, typically use algorithms called supervised decoders. These rely on simultaneous recording of both neural activity and moment-by-moment movement details, including limb position and speed--a time-consuming, laborious process. This information is then used to train the decoder to translate neural patterns into their corresponding movements. In cryptography terms, this would be like comparing a number of already decrypted messages with their encrypted versions to reverse engineer the key. In contrast, Dyer's team sought to predict movements using only the "encrypted messages" (neural activity) and a general understanding of the patterns that pop up in certain movements. The scientists trained three macaques to use arm or wrist movements to guide a cursor to a number of targets on a screen. At the same time, implanted electrodes recorded signals from about 100 neurons in each monkey's motor cortex--a brain region that controls movement. The researchers then tested a slew of computational models to find the one that best mapped patterns buried in the neural activity onto patterns they had seen in the animals' movements. When the researchers used their best model to decode neural activity from individual trials, they could predict the macaques' actual movements on those trials about as well as some basic supervised decoders. "It's a very cool result," says Jonathan Kao, a computational neuroscientist at the University of California, Los Angeles, who was not involved in the study. Dyer calls her work a proof of concept and notes that much more must be done before the technique can be used widely. "By comparison to state-of-the-art decoders, this is not yet a competitive method," she says. "We've only kind of scratched the surface." Helen Shen is a science writer based in Sunnyvale, Calif. She has contributed to  and the . June 1, 2017  --  Knvul Sheikh March 24, 2017  --  Adam Piore April 27, 2017  --  Larry Greenemeier October 2, 2017  --  Craig P. Bauer Discover new insights into neuroscience, human behavior and mental health with Scientific American Mind. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.