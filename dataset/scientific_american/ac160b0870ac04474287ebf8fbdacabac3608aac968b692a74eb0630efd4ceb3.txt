Read Our Latest Issue Read Our Latest Issue Some experiments are simply too dangerous to warrant the risk Last October the White House announced a pause in federal funding for so-called gain-of-function experiments that increase the contagiousness or virulence of influenza viruses or of the coronaviruses that cause severe acute respiratory syndrome (SARS) or Middle East respiratory syndrome (MERS). With the announcement began a yearlong "deliberative process"; in the coming months a committee led by the National Science Advisory Board for Biosecurity and the National Research Council must advise the U.S. government on whether to continue funding research of this kind. The pause was long overdue. Mishaps in federal laboratories last summer reminded us that accidents happen in even the best facilities. Most dangerous pathogens under study in labs such as these are not highly transmissible, so the risk is largely confined to on-site workers. Gain-of-function experiments, especially those involving flu, are a different story. Since at least 2005, researchers have been deliberately creating influenza viruses that are both highly virulent (killing several percent or more of those infected) and spread easily among humans. The most dangerous experiments involve strains that are unfamiliar to our immune systems; neither our natural defenses nor existing vaccines can protect us against them. They are called potential pandemic pathogens (PPPs) because an accident involving their release could cause a global catastrophe. We must study dangerous pathogens if we want to defeat them. As scientists and as a society, we accept the low probability that a handful of people may become accidentally infected and even die doing necessary science. But experiments involving PPPs massively increase the stakes: they place the world's population at risk. The chances of a catastrophic event such as an accidental pandemic are hard to estimate, but preliminary work puts the risk at 0.01 to 0.1 percent per laboratory year of research on transmissible, virulent flu. Such a pandemic could claim millions of lives. We have never before knowingly accepted such risks for the sake of scientific experiments, and we need an exceptionally compelling rationale before we consider doing so now. Proponents of PPP experiments argue that by studying the properties of transmissible, virulent flu in the lab, we can better prepare for strains that become pandemic naturally--for example, by developing "prepandemic" vaccines. This idea is highly problematic. We are nowhere near being able to predict from a flu virus's genetic sequence whether it will be transmissible or virulent, and our surveillance of flu strains in the wild is extremely limited. The impact of a particular change to the genetic sequence of a flu virus depends, in ways we have barely begun to understand, on the rest of the flu genome. Our current approaches for pandemic risk prediction are largely untested, and they have never succeeded in identifying a strain as risky before a pandemic occurred. Researchers began discussing the novel risks of PPP experiments a decade ago, but the conversation quickly stalled; thereafter, PPP research steamed ahead. The pause in U.S. funding at last gives us an opportunity to have that debate. The U.S. is not the only funder of this type of research, but it is a major one, and the rest of the world will be watching carefully. The scientists and policy makers involved in the White House's deliberative process must carefully consider the risks and benefits of potential pandemic pathogens. The choice is not between studying these pathogens and ignoring them. The choice is between a portfolio of research, technology development and surveillance that includes PPP studies and a portfolio that excludes PPP research and uses the freed-up resources for alternatives. The creation of novel, transmissible, virulent influenza strains is exceptionally risky and has little public health benefit; such research should be stopped. Other types of experiments included in the funding pause, among them those that alter MERS and SARS viruses to adapt them to lab animals, might be different. For all such studies, however, objective, credible, disinterested and quantitative risk-benefit analysis is needed before further experiments continue. This article was originally published with the title "Defusing a Biological Bomb" in Scientific American  312, 2, 14 (February 2015) doi:10.1038/scientificamerican0215-14 Marc Lipsitch is a professor of epidemiology and director of the Center for Communicable Disease Dynamics at the Harvard T. H. Chan School of Public Health. Credit: Nick Higgins 6 hours ago  --  Robert Z. Pearlman and SPACE.com 7 hours ago  --  Nidhi Subbaraman and Nature magazine 8 hours ago  --  Jean Chemnick and E&E News 14 hours ago  --  Avi Loeb | 15 hours ago  --  Marla Broadfoot January 25, 2021  --  Chelsea Harvey and E&E News Discover world-changing science. Explore our digital archive back to 1845, including articles by more than 150 Nobel Prize winners. Follow us Scientific american arabic (c) 2021 Scientific American, a Division of Springer Nature America, Inc. All Rights Reserved. Support our award-winning coverage of advances in science & technology. Already a subscriber? Subscribers get more award-winning coverage of advances in science & technology.